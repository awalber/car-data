{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Car Data Exploration\r\n",
    "## Author: Aaron Walber\r\n",
    "### Email: awalber94@gmail.com\r\n",
    "#### Start by Importing all relevant python packages"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Examine the data\r\n",
    "To view the data, first it will be loaded into pandas. Initial examination shows that the data is semi-colon delimited\r\n",
    "with an additional row after the column names indicating the data types.\r\n",
    "\r\n",
    "Please note that this notebook will assume that the data is contained in the same folder as this notebook"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = pd.read_csv(\"cars.csv\",delimiter=\";\",skiprows=[1])\r\n",
    "# drop rows which contain an NaN value\r\n",
    "df.dropna(axis=0)\r\n",
    "df.head(10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pick out some important features of the data\r\n",
    "\r\n",
    "Finding the car with the highest MPG can be performed by simply selecting the MPG columns and searching for the maximum. Finding a maximum in an unsorted list is always going to be O(n) operations. In this case, we want the index of the maximum so that value can be pulled out of an array. In general, referencing something by a lookup value in a pandas dataframe will always be slower than indexing it."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# create a numpy array out of the MPG column\r\n",
    "mpg = df[\"MPG\"].values\r\n",
    "max_mpg = np.argmax(mpg)\r\n",
    "max_mpg # the maximum mpg index\r\n",
    "# finally, utilize this index to grab the entire row for this vehicle\r\n",
    "df.iloc[max_mpg]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "From running the snippet above, we can see that the car with the maximum MPG is a Mazda GLC, which is made in Japan. We can also examine some other important aspects of this vehicle which might prove useful in predicting the MPG. For example, the weight of the vehicle most likely plays an important factor as well as the displacement, number of cyliders, acceleration, and horsepower.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Find the average MPG per cylinder count:\r\n",
    "\r\n",
    "This can be done by performing a vectorized operation between two arrays."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# create numpy arrays from these two columns\r\n",
    "cylinders = df[\"Cylinders\"].values\r\n",
    "mpgs = df[\"MPG\"].values\r\n",
    "# perform a vectorized divide on each item in mpg with each item from cylinders\r\n",
    "mpg_per_cylinder = mpgs/cylinders\r\n",
    "# the average MPG/cylinder for the entire CSV will be a mean of the variable mpg_per_cylinder\r\n",
    "print(\"The average MPG per cylinder is {}\".format(np.mean(mpg_per_cylinder)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Find the average MPG for each Manufacturer\r\n",
    "\r\n",
    "This could be important information when trying to decide which car best suits your needs. Obviously if one manufacturer has a consistently higher MPG than their competition, this could weigh in to a decision made by a consumer.\r\n",
    "\r\n",
    "From our earlier examination of the data, the manufacturer isn't a direct column in the data. This means we will need to extract it from the \"Car\" column. It might be helpful to save this out as a separate column in itself in case this is needed later.\r\n",
    "\r\n",
    "This information will be stored in a dictionary because each key can represent the car manufacturer and each value can be a list of cars found in this CSV."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "makes = []\r\n",
    "print(df)\r\n",
    "for row,car in enumerate(df[\"Car\"]):\r\n",
    "    make = car.split(\" \")[0]\r\n",
    "    if make.endswith(\" \"):\r\n",
    "        make = make[:-1]\r\n",
    "    makes.append(make)\r\n",
    "df[\"Make\"] = makes\r\n",
    "df.head(5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that the make has been added to the dataframe. Now all that's left is to group the dataframe by each unique \"Make\" value and calculate the average MPG. This information can be stored in a dictionary."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "avg_mpg = {}\r\n",
    "for make,_df in df.groupby(\"Make\"):\r\n",
    "    avg_mpg[make] = np.mean(_df[\"MPG\"].values)\r\n",
    "avg_mpg"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Examining the dictionary shows Nissan has the highest average MPG with 36 and the lowest average MPG as Citroen at 0 MPG. Perhaps this is a mistake in the data because examining the only car for this make yields the following results:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df[df[\"Make\"]==\"Citroen\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build a Model to Predict MPG\r\n",
    "\r\n",
    "As stated previously, this will probably be best performed by looking at the following factors:\r\n",
    "* Cylinders\r\n",
    "* Displacement\r\n",
    "* Horsepower\r\n",
    "* Weight\r\n",
    "* Acceleration\r\n",
    "\r\n",
    "Obviously MPG would be the dependent variable in examining these other variables. Values like Make seem to be indicative, but without a larger sample size for certain makes, this would quickly lead to overfitting on any new data.\r\n",
    "\r\n",
    "A decent approach to figuring out if these should be used would be to create a plot of every value against the MPG value to determine if they are correlated or not. A strong correlation means that these values should definitely be used. Plotting assists with this to help identify the type of correlation, because it could be linear, nonlinear, or not correlated at all."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mpg = df[\"MPG\"].values\r\n",
    "independent_vars = {name:df[name].values for name in [\"Cylinders\",\"Displacement\",\"Horsepower\",\"Weight\",\"Acceleration\"]}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plot the relationships between MPG and the other identified variables\r\n",
    "\r\n",
    "Here, MPG will be plotted on the y-axis and the other variable will be plotted on the x-axis."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "for name,arr in independent_vars.items():\r\n",
    "    plt.scatter(arr,mpg)\r\n",
    "    plt.xlabel(name)\r\n",
    "    plt.ylabel(\"MPG\")\r\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Insights from Plotting the Data\r\n",
    "\r\n",
    "Plotting the data immediately reveals a lot of important information. First off, there are some erroneous values for MPG that should be removed. The MPG of a vehicle can not physically be 0, and attempting to train on this value would only mislead the model. These plots also make it apparent that Cylinders and Acceleration would not be very good predictors of MPG since they would likely have low correlation with a linear or nonlinear model. On the other hand, Displacement, Horsepower, and Weight all seem to be somewhat correlated with MPG with some obvious outliers. It's also apparent that the relationship is definitely nonlinear for Horsepower. Displacement and Weight could arguably have either a linear or nonlinear relationship with MPG. To figure it out, let's take some simple regressions of this data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "non_zero_inds = np.where(mpg>0)\r\n",
    "mpg = mpg[non_zero_inds]\r\n",
    "independent_vars = {name:np.atleast_2d(value[non_zero_inds]).T for name,value in independent_vars.items() if name not in [\"Cylinders\",\"Acceleration\"]}\r\n",
    "mpg = np.atleast_2d(mpg).T"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "from sklearn.linear_model import LinearRegression\r\n",
    "for name,value in independent_vars.items():\r\n",
    "    linreg = LinearRegression()\r\n",
    "    reg = linreg.fit(value,mpg)\r\n",
    "    print(\"Linear regression r^2 value: {}, variable: {}\".format(linreg.score(value,mpg),name))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test out nonlinear regression scores\r\n",
    "\r\n",
    "The scores achieved by fitting the data were lower than anticipated, so we'll test all variables against a simple nonlinear model. A favorite nonlinear regressor of mine is Support Vector Regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# change mpg back to a 1d array\r\n",
    "mpg = mpg.reshape(mpg.shape[0])\r\n",
    "mpg.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.svm import SVR\r\n",
    "reg_params = [0.1,1.0,2.0,10.0,20]\r\n",
    "for c in reg_params:\r\n",
    "    for name,value in independent_vars.items():\r\n",
    "        reg_model = SVR(C=c)\r\n",
    "        reg = reg_model.fit(value,mpg)\r\n",
    "        print(\"SVR regression C value: {} r^2 value: {}, variable: {}\".format(c,reg_model.score(value,mpg),name))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The code above tests each variable utilizing a Radial Basis kernel function while changing the regularization. It's apparent that each of these fits performs better than the linear regression model, so it might be best to continue utilizing the SVR model. Setting the regularization to 10 seems to perform better than lower values, so we'll keep this. However there are some other parameters that can be tuned, like epsilon and tolerance"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# a higher value for epsilon could help to allow for the natural noise that appears in the data\r\n",
    "for eps in [1, 1e-1, 1e-2]:\r\n",
    "    for name,value in independent_vars.items():\r\n",
    "        reg_model = SVR(C=c,epsilon=eps)\r\n",
    "        reg = reg_model.fit(value,mpg)\r\n",
    "        print(\"SVR regression epsilon value: {} r^2 value: {}, variable: {}\".format(eps,reg_model.score(value,mpg),name))\r\n",
    "print()\r\n",
    "for tol in [1e-3, 1e-4, 1e-5]:\r\n",
    "    for name,value in independent_vars.items():\r\n",
    "        reg_model = SVR(C=c,tol=tol,epsilon=1)\r\n",
    "        reg = reg_model.fit(value,mpg)\r\n",
    "        print(\"SVR regression tolerance value: {} r^2 value: {}, variable: {}\".format(tol,reg_model.score(value,mpg),name))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tuning epsilon yields slightly better results, most likely from omitting the small amount of variance in the data. However, adjusting the tolerance doesn't produce a strikingly better result, so we'll keep the defaults other than C and epsilon, which should now be set to 10 and 1 respectively."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train the Model with the Adjusted Hyper-Parameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = SVR(C=10)\r\n",
    "X = np.concatenate([arr for arr in independent_vars.values()],axis=1)\r\n",
    "y = mpg\r\n",
    "model.fit(X,y)\r\n",
    "pred = model.predict(X)\r\n",
    "print(\"The r^2 value of this model is {}\".format(model.score(X,y)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualize the Predictions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "resids = abs(pred - mpg)\r\n",
    "plt.scatter(range(len(resids)),resids)\r\n",
    "plt.xlabel(\"Index of Car in Data\")\r\n",
    "plt.ylabel(\"Absolute Residual Value\")\r\n",
    "plt.title(\"Residuals for each Car's MPG and the Corresponding Prediction\")\r\n",
    "print(\"The average of the absolute residuals for the predictions is {}\".format(np.mean(resids)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Other Error Metrics:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.metrics import max_error, mean_squared_error\r\n",
    "\r\n",
    "print(\"The maximum Error in the Predictions is {}\".format(max_error(mpg,pred)))\r\n",
    "print(\"The MAE of the Predictions is {}\".format(mean_squared_error(mpg,pred)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conclusion\r\n",
    "\r\n",
    "Inspecting the data revealed a slightly noisy but very manageable dataset. The obvious problem in predicting the MPG of each car was that some of the MPG values were 0, which indicates a bad data point since this value shouldn't ever be 0. This model was trained and tested without those data points to avoid unnecessary error in predictions. However, no prediction was made on these missing data points because any prediction made would likely be erroneous anyway.\r\n",
    "\r\n",
    "The error in the model is acceptable, except there is no testing data to confirm these predictions. Obviously the Support Vector Regression model utilizes a cross-validation set, and achieved a very low value for the average absolute residual between the ground truth MPG and the predicted value. When comparing this error against the variability of the data (excluding the trend) the model was trained on, it's clear the model reached the threshold where any further error could be considered irreducible error. Essentially, when regressing Weight, Displacement, and Horsepower against the MPG, the perfect fit would still have an absolute error between 5 and 20 just by visual inspection. Thus, utilizing a regression model that combined all 3 of the independent variables to predict the MPG improved performance a significant amount without overfitting the data."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.12 64-bit ('aimpoint': conda)"
  },
  "interpreter": {
   "hash": "0bcbf86edad7cb0bfcf854dbdf875f5645ed11abd491044573d8b60c66002fad"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}